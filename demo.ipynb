{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d31573c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REFERENCE TEXT:\n",
      " My father made him an offer he could not refuse Held a gun to his head and assured him that either his brain or his signature would be on the contract True story\n",
      "\n",
      "RECOGNIZED TEXT:\n",
      " My father may his another he could den refuse Held a gone to gist head and azure Ed his that either his brain or his signature would be on the contract Truth toy\n",
      "\n",
      "======================================================================\n",
      "WORD-LEVEL ALIGNMENT (REF → HYP)\n",
      "======================================================================\n",
      "CORRECT : My\n",
      "CORRECT : father\n",
      "DEL     : made  →  <eps>\n",
      "SUB     : him  →  may\n",
      "SUB     : an  →  his\n",
      "SUB     : offer  →  another\n",
      "CORRECT : he\n",
      "CORRECT : could\n",
      "SUB     : not  →  den\n",
      "CORRECT : refuse\n",
      "CORRECT : Held\n",
      "CORRECT : a\n",
      "SUB     : gun  →  gone\n",
      "CORRECT : to\n",
      "SUB     : his  →  gist\n",
      "CORRECT : head\n",
      "CORRECT : and\n",
      "INS     : <eps> →  azure\n",
      "SUB     : assured  →  Ed\n",
      "SUB     : him  →  his\n",
      "CORRECT : that\n",
      "CORRECT : either\n",
      "CORRECT : his\n",
      "CORRECT : brain\n",
      "CORRECT : or\n",
      "CORRECT : his\n",
      "CORRECT : signature\n",
      "CORRECT : would\n",
      "CORRECT : be\n",
      "CORRECT : on\n",
      "CORRECT : the\n",
      "CORRECT : contract\n",
      "SUB     : True  →  Truth\n",
      "SUB     : story  →  toy\n",
      "\n",
      "======================================================================\n",
      "WER: 36.36%\n",
      "WCR: 66.67%\n",
      "\n",
      "======================================================================\n",
      "Metrics for word 'his':\n",
      "Precision = 0.500\n",
      "Recall    = 0.667\n",
      "F1-score  = 0.571\n",
      "\n",
      "======================================================================\n",
      "ALIGNMENT SUMMARY\n",
      "======================================================================\n",
      "Correct     : 22\n",
      "Substitute  : 10\n",
      "Delete      : 1\n",
      "Insert      : 1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from collections import defaultdict\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "TARGET_WORD = \"his\"\n",
    "num_sentences = 1\n",
    "\n",
    "# =========================================================\n",
    "# FIXED INPUT TEXTS\n",
    "# =========================================================\n",
    "REFERENCE_TEXT = (\n",
    "    \"My father made him an offer he could not refuse Held a gun to his head and assured him that either his brain or his signature would be on the contract True story\"\n",
    ")\n",
    "\n",
    "RECOGNIZED_TEXT = (\n",
    "    \"My father may his another he could den refuse Held a gone to gist head and azure Ed his that either his brain or his signature would be on the contract Truth toy\"\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# Punctuation-aware tokenizer\n",
    "# =========================================================\n",
    "def tokenize_with_punctuation(text):\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
    "\n",
    "# =========================================================\n",
    "# Word-level alignment (Levenshtein)\n",
    "# =========================================================\n",
    "def align_words(ref_tokens, hyp_tokens):\n",
    "    n, m = len(ref_tokens), len(hyp_tokens)\n",
    "    dp = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "\n",
    "    for i in range(n + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(m + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            if ref_tokens[i - 1] == hyp_tokens[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(\n",
    "                    dp[i - 1][j],      # deletion\n",
    "                    dp[i][j - 1],      # insertion\n",
    "                    dp[i - 1][j - 1]   # substitution\n",
    "                )\n",
    "\n",
    "    i, j = n, m\n",
    "    ops = []\n",
    "    while i > 0 or j > 0:\n",
    "        if i > 0 and j > 0 and ref_tokens[i - 1] == hyp_tokens[j - 1]:\n",
    "            ops.append((\"CORRECT\", ref_tokens[i - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and j > 0 and dp[i][j] == dp[i - 1][j - 1] + 1:\n",
    "            ops.append((\"SUB\", ref_tokens[i - 1], hyp_tokens[j - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and dp[i][j] == dp[i - 1][j] + 1:\n",
    "            ops.append((\"DEL\", ref_tokens[i - 1]))\n",
    "            i -= 1\n",
    "        else:\n",
    "            ops.append((\"INS\", hyp_tokens[j - 1]))\n",
    "            j -= 1\n",
    "\n",
    "    return list(reversed(ops))\n",
    "\n",
    "# =========================================================\n",
    "# MAIN\n",
    "# =========================================================\n",
    "print(\"\\nREFERENCE TEXT:\\n\", REFERENCE_TEXT)\n",
    "print(\"\\nRECOGNIZED TEXT:\\n\", RECOGNIZED_TEXT)\n",
    "\n",
    "ref_tokens = tokenize_with_punctuation(REFERENCE_TEXT)\n",
    "rec_tokens = tokenize_with_punctuation(RECOGNIZED_TEXT)\n",
    "\n",
    "ops = align_words(ref_tokens, rec_tokens)\n",
    "\n",
    "# =========================================================\n",
    "# DISPLAY ALIGNMENT OPERATIONS\n",
    "# =========================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"WORD-LEVEL ALIGNMENT (REF → HYP)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for op in ops:\n",
    "    if op[0] == \"CORRECT\":\n",
    "        print(f\"CORRECT : {op[1]}\")\n",
    "    elif op[0] == \"SUB\":\n",
    "        print(f\"SUB     : {op[1]}  →  {op[2]}\")\n",
    "    elif op[0] == \"DEL\":\n",
    "        print(f\"DEL     : {op[1]}  →  <eps>\")\n",
    "    elif op[0] == \"INS\":\n",
    "        print(f\"INS     : <eps> →  {op[1]}\")\n",
    "\n",
    "# =========================================================\n",
    "# COUNT WORD-LEVEL METRICS\n",
    "# =========================================================\n",
    "word_counts = defaultdict(lambda: {\"TP\": 0, \"FP\": 0, \"FN\": 0})\n",
    "\n",
    "for op in ops:\n",
    "    if op[0] == \"CORRECT\":\n",
    "        word_counts[op[1]][\"TP\"] += 1\n",
    "    elif op[0] == \"SUB\":\n",
    "        ref_w, hyp_w = op[1], op[2]\n",
    "        word_counts[ref_w][\"FN\"] += 1\n",
    "        word_counts[hyp_w][\"FP\"] += 1\n",
    "    elif op[0] == \"DEL\":\n",
    "        word_counts[op[1]][\"FN\"] += 1\n",
    "    elif op[0] == \"INS\":\n",
    "        word_counts[op[1]][\"FP\"] += 1\n",
    "\n",
    "# =========================================================\n",
    "# WER / WCR\n",
    "# =========================================================\n",
    "subs = sum(1 for o in ops if o[0] == \"SUB\")\n",
    "dels = sum(1 for o in ops if o[0] == \"DEL\")\n",
    "ins  = sum(1 for o in ops if o[0] == \"INS\")\n",
    "\n",
    "wer = (subs + dels + ins) / len(ref_tokens)\n",
    "wcr = (len(ref_tokens) - subs - dels) / len(ref_tokens)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"WER: {wer:.2%}\")\n",
    "print(f\"WCR: {wcr:.2%}\")\n",
    "\n",
    "# =========================================================\n",
    "# PER-WORD METRICS\n",
    "# =========================================================\n",
    "TP = word_counts[TARGET_WORD][\"TP\"]\n",
    "FP = word_counts[TARGET_WORD][\"FP\"]\n",
    "FN = word_counts[TARGET_WORD][\"FN\"]\n",
    "\n",
    "precision = TP / (TP + FP) if TP + FP > 0 else 0.0\n",
    "recall    = TP / (TP + FN) if TP + FN > 0 else 0.0\n",
    "f1        = (2 * precision * recall / (precision + recall)) if precision + recall > 0 else 0.0\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Metrics for word '{TARGET_WORD}':\")\n",
    "print(f\"Precision = {precision:.3f}\")\n",
    "print(f\"Recall    = {recall:.3f}\")\n",
    "print(f\"F1-score  = {f1:.3f}\")\n",
    "\n",
    "# =========================================================\n",
    "# SUMMARY COUNTS\n",
    "# =========================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALIGNMENT SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Correct     : {sum(1 for o in ops if o[0]=='CORRECT')}\")\n",
    "print(f\"Substitute  : {subs}\")\n",
    "print(f\"Delete      : {dels}\")\n",
    "print(f\"Insert      : {ins}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0def3cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ayham/.cache\\torch\\hub\\snakers4_silero-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing sentence 1\n",
      "============================================================\n",
      "\n",
      "Reference text: The Annual Bulletin of the Comparative Law Bureau of the American Bar Association was an American specialty law journal.\n",
      "Recognized text: the annual bulletin of the comparative law bureau of the american bar association was an american specialty law journal\n",
      "WER: 55.00%, WCR: 45.00%, Audio dur: 7.85s, Processing: 0.87s, RTF: 0.111\n",
      "\n",
      "============================================================\n",
      "Metrics for word 'the': Precision=0.667, Recall=1.000, F1=0.800\n",
      "\n",
      "Macro-averaged: Precision=0.257, Recall=0.292\n",
      "Micro-averaged: Precision=0.474, Recall=0.450\n",
      "\n",
      "============================================================\n",
      "AVERAGE WER: 55.00%\n",
      "AVERAGE WCR: 45.00%\n",
      "AVERAGE RTF: 0.111\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from scipy.signal import resample_poly\n",
    "from collections import defaultdict\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "TARGET_WORD = \"the\"   # word of interest (case-sensitive)\n",
    "audio_dir = r\"C:\\Users\\ayham\\Desktop\\Downloads\\live_demo_dataset\\task2_c_m.wav\"\n",
    "transcript_path = r\"C:\\Users\\ayham\\Speech-Recognation-App\\2-c.txt\"\n",
    "num_sentences = 1\n",
    "\n",
    "# =========================================================\n",
    "# Load reference sentence by ID\n",
    "# =========================================================\n",
    "def load_reference_by_id(path: str, sentence_id: int) -> str:\n",
    "    prefix = f\"{sentence_id}:\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(prefix):\n",
    "                text = line[len(prefix):].strip()\n",
    "                text = re.sub(r\"\\(.*?\\)\", \"\", text).strip()\n",
    "                return text\n",
    "    raise ValueError(f\"Sentence ID {sentence_id} not found in transcript file\")\n",
    "\n",
    "# =========================================================\n",
    "# Punctuation-aware tokenizer\n",
    "# =========================================================\n",
    "def tokenize_with_punctuation(text: str) -> list[str]:\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
    "\n",
    "# =========================================================\n",
    "# Word-level alignment (Levenshtein)\n",
    "# =========================================================\n",
    "def align_words(ref_tokens, hyp_tokens):\n",
    "    n, m = len(ref_tokens), len(hyp_tokens)\n",
    "    dp = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "\n",
    "    for i in range(n + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(m + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            if ref_tokens[i - 1] == hyp_tokens[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(\n",
    "                    dp[i - 1][j],\n",
    "                    dp[i][j - 1],\n",
    "                    dp[i - 1][j - 1]\n",
    "                )\n",
    "\n",
    "    i, j = n, m\n",
    "    ops = []\n",
    "    while i > 0 or j > 0:\n",
    "        if i > 0 and j > 0 and ref_tokens[i - 1] == hyp_tokens[j - 1]:\n",
    "            ops.append((\"CORRECT\", ref_tokens[i - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and j > 0 and dp[i][j] == dp[i - 1][j - 1] + 1:\n",
    "            ops.append((\"SUB\", ref_tokens[i - 1], hyp_tokens[j - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and dp[i][j] == dp[i - 1][j] + 1:\n",
    "            ops.append((\"DEL\", ref_tokens[i - 1]))\n",
    "            i -= 1\n",
    "        else:\n",
    "            ops.append((\"INS\", hyp_tokens[j - 1]))\n",
    "            j -= 1\n",
    "\n",
    "    return reversed(ops)\n",
    "\n",
    "# =========================================================\n",
    "# Silero STT transcription\n",
    "# =========================================================\n",
    "def transcribe_audio(model, decoder, prepare_model_input, path: str):\n",
    "    start_time = time.time()\n",
    "    audio, sr = sf.read(path)\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    if sr != 16000:\n",
    "        audio = resample_poly(audio, 16000, sr)\n",
    "        sr = 16000\n",
    "\n",
    "    audio_tensor = torch.from_numpy(audio).float().unsqueeze(0)\n",
    "    input_tensor = prepare_model_input(audio_tensor, device=\"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    recognized_text = decoder(output[0].cpu())\n",
    "    processing_time = time.time() - start_time\n",
    "    return recognized_text, processing_time, len(audio)/sr\n",
    "\n",
    "# =========================================================\n",
    "# MAIN\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    wer_list, wcr_list, rtf_list = [], [], []\n",
    "    total_wer, total_wcr, total_rtf = 0.0, 0.0, 0.0\n",
    "\n",
    "    # Word-level counts for all words\n",
    "    word_counts = defaultdict(lambda: {\"TP\":0, \"FP\":0, \"FN\":0})\n",
    "\n",
    "    # =============================\n",
    "    # Load Silero model ONCE\n",
    "    # =============================\n",
    "    device = torch.device(\"cpu\")\n",
    "    model, decoder, utils = torch.hub.load(\n",
    "        repo_or_dir=\"snakers4/silero-models\",\n",
    "        model=\"silero_stt\",\n",
    "        language=\"en\",\n",
    "        device=device\n",
    "    )\n",
    "    (_, _, _, prepare_model_input) = utils\n",
    "\n",
    "    # =============================\n",
    "    # Process each sentence\n",
    "    # =============================\n",
    "    for sentence_id in range(1, num_sentences+1):\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"Processing sentence {sentence_id}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        audio_path = audio_dir\n",
    "\n",
    "        reference_text = load_reference_by_id(transcript_path, sentence_id)\n",
    "        print(\"\\nReference text:\", reference_text)\n",
    "\n",
    "        recognized_text, processing_time, audio_duration = transcribe_audio(model, decoder, prepare_model_input, audio_path)\n",
    "        print(\"Recognized text:\", recognized_text)\n",
    "\n",
    "        ref_tokens = tokenize_with_punctuation(reference_text)\n",
    "        rec_tokens = tokenize_with_punctuation(recognized_text)\n",
    "\n",
    "        ops = list(align_words(ref_tokens, rec_tokens))\n",
    "\n",
    "        # Update word-level counts\n",
    "        for op in ops:\n",
    "            if op[0] == \"CORRECT\":\n",
    "                word_counts[op[1]][\"TP\"] += 1\n",
    "            elif op[0] == \"SUB\":\n",
    "                ref_w, hyp_w = op[1], op[2]\n",
    "                word_counts[ref_w][\"FN\"] += 1\n",
    "                word_counts[hyp_w][\"FP\"] += 1\n",
    "            elif op[0] == \"DEL\":\n",
    "                word_counts[op[1]][\"FN\"] += 1\n",
    "            elif op[0] == \"INS\":\n",
    "                word_counts[op[1]][\"FP\"] += 1\n",
    "\n",
    "        # WER/WCR\n",
    "        subs = sum(1 for o in ops if o[0]==\"SUB\")\n",
    "        dels = sum(1 for o in ops if o[0]==\"DEL\")\n",
    "        ins = sum(1 for o in ops if o[0]==\"INS\")\n",
    "        wer = (subs + dels + ins)/len(ref_tokens)\n",
    "        wcr = (len(ref_tokens) - subs - dels)/len(ref_tokens)\n",
    "\n",
    "        wer_list.append(wer)\n",
    "        wcr_list.append(wcr)\n",
    "        total_wer += wer\n",
    "        total_wcr += wcr\n",
    "        rtf = processing_time / audio_duration\n",
    "        rtf_list.append(rtf)\n",
    "        total_rtf += rtf\n",
    "\n",
    "        print(f\"WER: {wer:.2%}, WCR: {wcr:.2%}, Audio dur: {audio_duration:.2f}s, Processing: {processing_time:.2f}s, RTF: {rtf:.3f}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # Per-word metrics for TARGET_WORD\n",
    "    # =========================================================\n",
    "    TP = word_counts[TARGET_WORD][\"TP\"]\n",
    "    FP = word_counts[TARGET_WORD][\"FP\"]\n",
    "    FN = word_counts[TARGET_WORD][\"FN\"]\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    f1 = (2*precision*recall/(precision+recall)) if (precision+recall) > 0 else 0.0\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Metrics for word '{TARGET_WORD}': Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # Macro / Micro averages over vocabulary\n",
    "    # =========================================================\n",
    "    macro_prec = 0.0\n",
    "    macro_rec = 0.0\n",
    "    for w, counts in word_counts.items():\n",
    "        TP_w, FP_w, FN_w = counts[\"TP\"], counts[\"FP\"], counts[\"FN\"]\n",
    "        macro_prec += TP_w / (TP_w + FP_w) if (TP_w + FP_w) > 0 else 0\n",
    "        macro_rec += TP_w / (TP_w + FN_w) if (TP_w + FN_w) > 0 else 0\n",
    "    macro_prec /= len(word_counts)\n",
    "    macro_rec /= len(word_counts)\n",
    "\n",
    "    total_TP = sum(c[\"TP\"] for c in word_counts.values())\n",
    "    total_FP = sum(c[\"FP\"] for c in word_counts.values())\n",
    "    total_FN = sum(c[\"FN\"] for c in word_counts.values())\n",
    "    micro_prec = total_TP / (total_TP + total_FP) if (total_TP + total_FP) > 0 else 0\n",
    "    micro_rec = total_TP / (total_TP + total_FN) if (total_TP + total_FN) > 0 else 0\n",
    "\n",
    "    print(\"\\nMacro-averaged: Precision={:.3f}, Recall={:.3f}\".format(macro_prec, macro_rec))\n",
    "    print(\"Micro-averaged: Precision={:.3f}, Recall={:.3f}\".format(micro_prec, micro_rec))\n",
    "\n",
    "    # =========================================================\n",
    "    # Average WER/WCR/RTF\n",
    "    # =========================================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"AVERAGE WER: {total_wer/num_sentences:.2%}\")\n",
    "    print(f\"AVERAGE WCR: {total_wcr/num_sentences:.2%}\")\n",
    "    print(f\"AVERAGE RTF: {total_rtf/num_sentences:.3f}\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e3d16bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ayham/.cache\\torch\\hub\\snakers4_silero-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing sentence 1\n",
      "============================================================\n",
      "\n",
      "Reference text: The Annual Bulletin of the Comparative Law Bureau of the American Bar Association was an American specialty law journal.\n",
      "Recognized text: the annualbbalitin of the comparative labureau of the american bor association was an american specialty law journal\n",
      "WER: 55.00%, WCR: 45.00%, Audio dur: 8.96s, Processing: 0.96s, RTF: 0.107\n",
      "\n",
      "============================================================\n",
      "Metrics for word 'mute': Precision=0.000, Recall=0.000, F1=0.000\n",
      "\n",
      "Macro-averaged: Precision=0.278, Recall=0.292\n",
      "Micro-averaged: Precision=0.529, Recall=0.450\n",
      "\n",
      "============================================================\n",
      "AVERAGE WER: 55.00%\n",
      "AVERAGE WCR: 45.00%\n",
      "AVERAGE RTF: 0.107\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from scipy.signal import resample_poly\n",
    "from collections import defaultdict\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "TARGET_WORD = \"mute\"   # word of interest (case-sensitive)\n",
    "audio_dir = r\"C:\\Users\\ayham\\Desktop\\Downloads\\live_demo_dataset\\task2_c_f.wav\"\n",
    "transcript_path = r\"C:\\Users\\ayham\\Speech-Recognation-App\\2-c.txt\"\n",
    "num_sentences = 1\n",
    "\n",
    "# =========================================================\n",
    "# Load reference sentence by ID\n",
    "# =========================================================\n",
    "def load_reference_by_id(path: str, sentence_id: int) -> str:\n",
    "    prefix = f\"{sentence_id}:\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(prefix):\n",
    "                text = line[len(prefix):].strip()\n",
    "                text = re.sub(r\"\\(.*?\\)\", \"\", text).strip()\n",
    "                return text\n",
    "    raise ValueError(f\"Sentence ID {sentence_id} not found in transcript file\")\n",
    "\n",
    "# =========================================================\n",
    "# Punctuation-aware tokenizer\n",
    "# =========================================================\n",
    "def tokenize_with_punctuation(text: str) -> list[str]:\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
    "\n",
    "# =========================================================\n",
    "# Word-level alignment (Levenshtein)\n",
    "# =========================================================\n",
    "def align_words(ref_tokens, hyp_tokens):\n",
    "    n, m = len(ref_tokens), len(hyp_tokens)\n",
    "    dp = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "\n",
    "    for i in range(n + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(m + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            if ref_tokens[i - 1] == hyp_tokens[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(\n",
    "                    dp[i - 1][j],\n",
    "                    dp[i][j - 1],\n",
    "                    dp[i - 1][j - 1]\n",
    "                )\n",
    "\n",
    "    i, j = n, m\n",
    "    ops = []\n",
    "    while i > 0 or j > 0:\n",
    "        if i > 0 and j > 0 and ref_tokens[i - 1] == hyp_tokens[j - 1]:\n",
    "            ops.append((\"CORRECT\", ref_tokens[i - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and j > 0 and dp[i][j] == dp[i - 1][j - 1] + 1:\n",
    "            ops.append((\"SUB\", ref_tokens[i - 1], hyp_tokens[j - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and dp[i][j] == dp[i - 1][j] + 1:\n",
    "            ops.append((\"DEL\", ref_tokens[i - 1]))\n",
    "            i -= 1\n",
    "        else:\n",
    "            ops.append((\"INS\", hyp_tokens[j - 1]))\n",
    "            j -= 1\n",
    "\n",
    "    return reversed(ops)\n",
    "\n",
    "# =========================================================\n",
    "# Silero STT transcription\n",
    "# =========================================================\n",
    "def transcribe_audio(model, decoder, prepare_model_input, path: str):\n",
    "    start_time = time.time()\n",
    "    audio, sr = sf.read(path)\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    if sr != 16000:\n",
    "        audio = resample_poly(audio, 16000, sr)\n",
    "        sr = 16000\n",
    "\n",
    "    audio_tensor = torch.from_numpy(audio).float().unsqueeze(0)\n",
    "    input_tensor = prepare_model_input(audio_tensor, device=\"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    recognized_text = decoder(output[0].cpu())\n",
    "    processing_time = time.time() - start_time\n",
    "    return recognized_text, processing_time, len(audio)/sr\n",
    "\n",
    "# =========================================================\n",
    "# MAIN\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    wer_list, wcr_list, rtf_list = [], [], []\n",
    "    total_wer, total_wcr, total_rtf = 0.0, 0.0, 0.0\n",
    "\n",
    "    # Word-level counts for all words\n",
    "    word_counts = defaultdict(lambda: {\"TP\":0, \"FP\":0, \"FN\":0})\n",
    "\n",
    "    # =============================\n",
    "    # Load Silero model ONCE\n",
    "    # =============================\n",
    "    device = torch.device(\"cpu\")\n",
    "    model, decoder, utils = torch.hub.load(\n",
    "        repo_or_dir=\"snakers4/silero-models\",\n",
    "        model=\"silero_stt\",\n",
    "        language=\"en\",\n",
    "        device=device\n",
    "    )\n",
    "    (_, _, _, prepare_model_input) = utils\n",
    "\n",
    "    # =============================\n",
    "    # Process each sentence\n",
    "    # =============================\n",
    "    for sentence_id in range(1, num_sentences+1):\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"Processing sentence {sentence_id}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        audio_path = audio_dir\n",
    "\n",
    "        reference_text = load_reference_by_id(transcript_path, sentence_id)\n",
    "        print(\"\\nReference text:\", reference_text)\n",
    "\n",
    "        recognized_text, processing_time, audio_duration = transcribe_audio(model, decoder, prepare_model_input, audio_path)\n",
    "        print(\"Recognized text:\", recognized_text)\n",
    "\n",
    "        ref_tokens = tokenize_with_punctuation(reference_text)\n",
    "        rec_tokens = tokenize_with_punctuation(recognized_text)\n",
    "\n",
    "        ops = list(align_words(ref_tokens, rec_tokens))\n",
    "\n",
    "        # Update word-level counts\n",
    "        for op in ops:\n",
    "            if op[0] == \"CORRECT\":\n",
    "                word_counts[op[1]][\"TP\"] += 1\n",
    "            elif op[0] == \"SUB\":\n",
    "                ref_w, hyp_w = op[1], op[2]\n",
    "                word_counts[ref_w][\"FN\"] += 1\n",
    "                word_counts[hyp_w][\"FP\"] += 1\n",
    "            elif op[0] == \"DEL\":\n",
    "                word_counts[op[1]][\"FN\"] += 1\n",
    "            elif op[0] == \"INS\":\n",
    "                word_counts[op[1]][\"FP\"] += 1\n",
    "\n",
    "        # WER/WCR\n",
    "        subs = sum(1 for o in ops if o[0]==\"SUB\")\n",
    "        dels = sum(1 for o in ops if o[0]==\"DEL\")\n",
    "        ins = sum(1 for o in ops if o[0]==\"INS\")\n",
    "        wer = (subs + dels + ins)/len(ref_tokens)\n",
    "        wcr = (len(ref_tokens) - subs - dels)/len(ref_tokens)\n",
    "\n",
    "        wer_list.append(wer)\n",
    "        wcr_list.append(wcr)\n",
    "        total_wer += wer\n",
    "        total_wcr += wcr\n",
    "        rtf = processing_time / audio_duration\n",
    "        rtf_list.append(rtf)\n",
    "        total_rtf += rtf\n",
    "\n",
    "        print(f\"WER: {wer:.2%}, WCR: {wcr:.2%}, Audio dur: {audio_duration:.2f}s, Processing: {processing_time:.2f}s, RTF: {rtf:.3f}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # Per-word metrics for TARGET_WORD\n",
    "    # =========================================================\n",
    "    TP = word_counts[TARGET_WORD][\"TP\"]\n",
    "    FP = word_counts[TARGET_WORD][\"FP\"]\n",
    "    FN = word_counts[TARGET_WORD][\"FN\"]\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    f1 = (2*precision*recall/(precision+recall)) if (precision+recall) > 0 else 0.0\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Metrics for word '{TARGET_WORD}': Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # Macro / Micro averages over vocabulary\n",
    "    # =========================================================\n",
    "    macro_prec = 0.0\n",
    "    macro_rec = 0.0\n",
    "    for w, counts in word_counts.items():\n",
    "        TP_w, FP_w, FN_w = counts[\"TP\"], counts[\"FP\"], counts[\"FN\"]\n",
    "        macro_prec += TP_w / (TP_w + FP_w) if (TP_w + FP_w) > 0 else 0\n",
    "        macro_rec += TP_w / (TP_w + FN_w) if (TP_w + FN_w) > 0 else 0\n",
    "    macro_prec /= len(word_counts)\n",
    "    macro_rec /= len(word_counts)\n",
    "\n",
    "    total_TP = sum(c[\"TP\"] for c in word_counts.values())\n",
    "    total_FP = sum(c[\"FP\"] for c in word_counts.values())\n",
    "    total_FN = sum(c[\"FN\"] for c in word_counts.values())\n",
    "    micro_prec = total_TP / (total_TP + total_FP) if (total_TP + total_FP) > 0 else 0\n",
    "    micro_rec = total_TP / (total_TP + total_FN) if (total_TP + total_FN) > 0 else 0\n",
    "\n",
    "    print(\"\\nMacro-averaged: Precision={:.3f}, Recall={:.3f}\".format(macro_prec, macro_rec))\n",
    "    print(\"Micro-averaged: Precision={:.3f}, Recall={:.3f}\".format(micro_prec, micro_rec))\n",
    "\n",
    "    # =========================================================\n",
    "    # Average WER/WCR/RTF\n",
    "    # =========================================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"AVERAGE WER: {total_wer/num_sentences:.2%}\")\n",
    "    print(f\"AVERAGE WCR: {total_wcr/num_sentences:.2%}\")\n",
    "    print(f\"AVERAGE RTF: {total_rtf/num_sentences:.3f}\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4af9783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ayham/.cache\\torch\\hub\\snakers4_silero-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing sentence 1\n",
      "============================================================\n",
      "\n",
      "Reference text: These take the shape of a long round arch with its path high above and its two ends apparently beyond the horizon.\n",
      "Recognized text: these take the shape of a long round arch with its path high above and its two ends apparently beyond the horizon\n",
      "WER: 8.70%, WCR: 91.30%, Audio dur: 7.85s, Processing: 0.96s, RTF: 0.122\n",
      "\n",
      "============================================================\n",
      "Metrics for word 'mute': Precision=0.000, Recall=0.000, F1=0.000\n",
      "\n",
      "Macro-averaged: Precision=0.826, Recall=0.826\n",
      "Micro-averaged: Precision=0.955, Recall=0.913\n",
      "\n",
      "============================================================\n",
      "AVERAGE WER: 8.70%\n",
      "AVERAGE WCR: 91.30%\n",
      "AVERAGE RTF: 0.122\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from scipy.signal import resample_poly\n",
    "from collections import defaultdict\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "TARGET_WORD = \"mute\"   # word of interest (case-sensitive)\n",
    "audio_dir = r\"C:\\Users\\ayham\\Desktop\\Downloads\\live_demo_dataset\\task2_b_f.wav\"\n",
    "transcript_path = r\"C:\\Users\\ayham\\Speech-Recognation-App\\2-b.txt\"\n",
    "num_sentences = 1\n",
    "\n",
    "# =========================================================\n",
    "# Load reference sentence by ID\n",
    "# =========================================================\n",
    "def load_reference_by_id(path: str, sentence_id: int) -> str:\n",
    "    prefix = f\"{sentence_id}:\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(prefix):\n",
    "                text = line[len(prefix):].strip()\n",
    "                text = re.sub(r\"\\(.*?\\)\", \"\", text).strip()\n",
    "                return text\n",
    "    raise ValueError(f\"Sentence ID {sentence_id} not found in transcript file\")\n",
    "\n",
    "# =========================================================\n",
    "# Punctuation-aware tokenizer\n",
    "# =========================================================\n",
    "def tokenize_with_punctuation(text: str) -> list[str]:\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
    "\n",
    "# =========================================================\n",
    "# Word-level alignment (Levenshtein)\n",
    "# =========================================================\n",
    "def align_words(ref_tokens, hyp_tokens):\n",
    "    n, m = len(ref_tokens), len(hyp_tokens)\n",
    "    dp = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "\n",
    "    for i in range(n + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(m + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            if ref_tokens[i - 1] == hyp_tokens[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(\n",
    "                    dp[i - 1][j],\n",
    "                    dp[i][j - 1],\n",
    "                    dp[i - 1][j - 1]\n",
    "                )\n",
    "\n",
    "    i, j = n, m\n",
    "    ops = []\n",
    "    while i > 0 or j > 0:\n",
    "        if i > 0 and j > 0 and ref_tokens[i - 1] == hyp_tokens[j - 1]:\n",
    "            ops.append((\"CORRECT\", ref_tokens[i - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and j > 0 and dp[i][j] == dp[i - 1][j - 1] + 1:\n",
    "            ops.append((\"SUB\", ref_tokens[i - 1], hyp_tokens[j - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and dp[i][j] == dp[i - 1][j] + 1:\n",
    "            ops.append((\"DEL\", ref_tokens[i - 1]))\n",
    "            i -= 1\n",
    "        else:\n",
    "            ops.append((\"INS\", hyp_tokens[j - 1]))\n",
    "            j -= 1\n",
    "\n",
    "    return reversed(ops)\n",
    "\n",
    "# =========================================================\n",
    "# Silero STT transcription\n",
    "# =========================================================\n",
    "def transcribe_audio(model, decoder, prepare_model_input, path: str):\n",
    "    start_time = time.time()\n",
    "    audio, sr = sf.read(path)\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    if sr != 16000:\n",
    "        audio = resample_poly(audio, 16000, sr)\n",
    "        sr = 16000\n",
    "\n",
    "    audio_tensor = torch.from_numpy(audio).float().unsqueeze(0)\n",
    "    input_tensor = prepare_model_input(audio_tensor, device=\"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    recognized_text = decoder(output[0].cpu())\n",
    "    processing_time = time.time() - start_time\n",
    "    return recognized_text, processing_time, len(audio)/sr\n",
    "\n",
    "# =========================================================\n",
    "# MAIN\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    wer_list, wcr_list, rtf_list = [], [], []\n",
    "    total_wer, total_wcr, total_rtf = 0.0, 0.0, 0.0\n",
    "\n",
    "    # Word-level counts for all words\n",
    "    word_counts = defaultdict(lambda: {\"TP\":0, \"FP\":0, \"FN\":0})\n",
    "\n",
    "    # =============================\n",
    "    # Load Silero model ONCE\n",
    "    # =============================\n",
    "    device = torch.device(\"cpu\")\n",
    "    model, decoder, utils = torch.hub.load(\n",
    "        repo_or_dir=\"snakers4/silero-models\",\n",
    "        model=\"silero_stt\",\n",
    "        language=\"en\",\n",
    "        device=device\n",
    "    )\n",
    "    (_, _, _, prepare_model_input) = utils\n",
    "\n",
    "    # =============================\n",
    "    # Process each sentence\n",
    "    # =============================\n",
    "    for sentence_id in range(1, num_sentences+1):\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"Processing sentence {sentence_id}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        audio_path = audio_dir\n",
    "\n",
    "        reference_text = load_reference_by_id(transcript_path, sentence_id)\n",
    "        print(\"\\nReference text:\", reference_text)\n",
    "\n",
    "        recognized_text, processing_time, audio_duration = transcribe_audio(model, decoder, prepare_model_input, audio_path)\n",
    "        print(\"Recognized text:\", recognized_text)\n",
    "\n",
    "        ref_tokens = tokenize_with_punctuation(reference_text)\n",
    "        rec_tokens = tokenize_with_punctuation(recognized_text)\n",
    "\n",
    "        ops = list(align_words(ref_tokens, rec_tokens))\n",
    "\n",
    "        # Update word-level counts\n",
    "        for op in ops:\n",
    "            if op[0] == \"CORRECT\":\n",
    "                word_counts[op[1]][\"TP\"] += 1\n",
    "            elif op[0] == \"SUB\":\n",
    "                ref_w, hyp_w = op[1], op[2]\n",
    "                word_counts[ref_w][\"FN\"] += 1\n",
    "                word_counts[hyp_w][\"FP\"] += 1\n",
    "            elif op[0] == \"DEL\":\n",
    "                word_counts[op[1]][\"FN\"] += 1\n",
    "            elif op[0] == \"INS\":\n",
    "                word_counts[op[1]][\"FP\"] += 1\n",
    "\n",
    "        # WER/WCR\n",
    "        subs = sum(1 for o in ops if o[0]==\"SUB\")\n",
    "        dels = sum(1 for o in ops if o[0]==\"DEL\")\n",
    "        ins = sum(1 for o in ops if o[0]==\"INS\")\n",
    "        wer = (subs + dels + ins)/len(ref_tokens)\n",
    "        wcr = (len(ref_tokens) - subs - dels)/len(ref_tokens)\n",
    "\n",
    "        wer_list.append(wer)\n",
    "        wcr_list.append(wcr)\n",
    "        total_wer += wer\n",
    "        total_wcr += wcr\n",
    "        rtf = processing_time / audio_duration\n",
    "        rtf_list.append(rtf)\n",
    "        total_rtf += rtf\n",
    "\n",
    "        print(f\"WER: {wer:.2%}, WCR: {wcr:.2%}, Audio dur: {audio_duration:.2f}s, Processing: {processing_time:.2f}s, RTF: {rtf:.3f}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # Per-word metrics for TARGET_WORD\n",
    "    # =========================================================\n",
    "    TP = word_counts[TARGET_WORD][\"TP\"]\n",
    "    FP = word_counts[TARGET_WORD][\"FP\"]\n",
    "    FN = word_counts[TARGET_WORD][\"FN\"]\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    f1 = (2*precision*recall/(precision+recall)) if (precision+recall) > 0 else 0.0\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Metrics for word '{TARGET_WORD}': Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # Macro / Micro averages over vocabulary\n",
    "    # =========================================================\n",
    "    macro_prec = 0.0\n",
    "    macro_rec = 0.0\n",
    "    for w, counts in word_counts.items():\n",
    "        TP_w, FP_w, FN_w = counts[\"TP\"], counts[\"FP\"], counts[\"FN\"]\n",
    "        macro_prec += TP_w / (TP_w + FP_w) if (TP_w + FP_w) > 0 else 0\n",
    "        macro_rec += TP_w / (TP_w + FN_w) if (TP_w + FN_w) > 0 else 0\n",
    "    macro_prec /= len(word_counts)\n",
    "    macro_rec /= len(word_counts)\n",
    "\n",
    "    total_TP = sum(c[\"TP\"] for c in word_counts.values())\n",
    "    total_FP = sum(c[\"FP\"] for c in word_counts.values())\n",
    "    total_FN = sum(c[\"FN\"] for c in word_counts.values())\n",
    "    micro_prec = total_TP / (total_TP + total_FP) if (total_TP + total_FP) > 0 else 0\n",
    "    micro_rec = total_TP / (total_TP + total_FN) if (total_TP + total_FN) > 0 else 0\n",
    "\n",
    "    print(\"\\nMacro-averaged: Precision={:.3f}, Recall={:.3f}\".format(macro_prec, macro_rec))\n",
    "    print(\"Micro-averaged: Precision={:.3f}, Recall={:.3f}\".format(micro_prec, micro_rec))\n",
    "\n",
    "    # =========================================================\n",
    "    # Average WER/WCR/RTF\n",
    "    # =========================================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"AVERAGE WER: {total_wer/num_sentences:.2%}\")\n",
    "    print(f\"AVERAGE WCR: {total_wcr/num_sentences:.2%}\")\n",
    "    print(f\"AVERAGE RTF: {total_rtf/num_sentences:.3f}\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b493bb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ayham/.cache\\torch\\hub\\snakers4_silero-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing sentence 1\n",
      "============================================================\n",
      "\n",
      "Reference text: The Annual Bulletin of the Comparative Law Bureau of the American Bar Association was an American specialty law journal.\n",
      "Recognized text: the annualbbalitin of the comparative labureau of the american bor association was an american specialty law journal\n",
      "WER: 55.00%, WCR: 45.00%, Audio dur: 8.96s, Processing: 0.83s, RTF: 0.093\n",
      "\n",
      "============================================================\n",
      "Metrics for word 'mute': Precision=0.000, Recall=0.000, F1=0.000\n",
      "\n",
      "Macro-averaged: Precision=0.278, Recall=0.292\n",
      "Micro-averaged: Precision=0.529, Recall=0.450\n",
      "\n",
      "============================================================\n",
      "AVERAGE WER: 55.00%\n",
      "AVERAGE WCR: 45.00%\n",
      "AVERAGE RTF: 0.093\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from scipy.signal import resample_poly\n",
    "from collections import defaultdict\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "TARGET_WORD = \"mute\"   # word of interest (case-sensitive)\n",
    "audio_dir = r\"C:\\Users\\ayham\\Desktop\\Downloads\\live_demo_dataset\\task2_c_f.wav\"\n",
    "transcript_path = r\"C:\\Users\\ayham\\Speech-Recognation-App\\2-c.txt\"\n",
    "num_sentences = 1\n",
    "\n",
    "# =========================================================\n",
    "# Load reference sentence by ID\n",
    "# =========================================================\n",
    "def load_reference_by_id(path: str, sentence_id: int) -> str:\n",
    "    prefix = f\"{sentence_id}:\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(prefix):\n",
    "                text = line[len(prefix):].strip()\n",
    "                text = re.sub(r\"\\(.*?\\)\", \"\", text).strip()\n",
    "                return text\n",
    "    raise ValueError(f\"Sentence ID {sentence_id} not found in transcript file\")\n",
    "\n",
    "# =========================================================\n",
    "# Punctuation-aware tokenizer\n",
    "# =========================================================\n",
    "def tokenize_with_punctuation(text: str) -> list[str]:\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
    "\n",
    "# =========================================================\n",
    "# Word-level alignment (Levenshtein)\n",
    "# =========================================================\n",
    "def align_words(ref_tokens, hyp_tokens):\n",
    "    n, m = len(ref_tokens), len(hyp_tokens)\n",
    "    dp = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "\n",
    "    for i in range(n + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(m + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            if ref_tokens[i - 1] == hyp_tokens[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(\n",
    "                    dp[i - 1][j],\n",
    "                    dp[i][j - 1],\n",
    "                    dp[i - 1][j - 1]\n",
    "                )\n",
    "\n",
    "    i, j = n, m\n",
    "    ops = []\n",
    "    while i > 0 or j > 0:\n",
    "        if i > 0 and j > 0 and ref_tokens[i - 1] == hyp_tokens[j - 1]:\n",
    "            ops.append((\"CORRECT\", ref_tokens[i - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and j > 0 and dp[i][j] == dp[i - 1][j - 1] + 1:\n",
    "            ops.append((\"SUB\", ref_tokens[i - 1], hyp_tokens[j - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and dp[i][j] == dp[i - 1][j] + 1:\n",
    "            ops.append((\"DEL\", ref_tokens[i - 1]))\n",
    "            i -= 1\n",
    "        else:\n",
    "            ops.append((\"INS\", hyp_tokens[j - 1]))\n",
    "            j -= 1\n",
    "\n",
    "    return reversed(ops)\n",
    "\n",
    "# =========================================================\n",
    "# Silero STT transcription\n",
    "# =========================================================\n",
    "def transcribe_audio(model, decoder, prepare_model_input, path: str):\n",
    "    start_time = time.time()\n",
    "    audio, sr = sf.read(path)\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    if sr != 16000:\n",
    "        audio = resample_poly(audio, 16000, sr)\n",
    "        sr = 16000\n",
    "\n",
    "    audio_tensor = torch.from_numpy(audio).float().unsqueeze(0)\n",
    "    input_tensor = prepare_model_input(audio_tensor, device=\"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    recognized_text = decoder(output[0].cpu())\n",
    "    processing_time = time.time() - start_time\n",
    "    return recognized_text, processing_time, len(audio)/sr\n",
    "\n",
    "# =========================================================\n",
    "# MAIN\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    wer_list, wcr_list, rtf_list = [], [], []\n",
    "    total_wer, total_wcr, total_rtf = 0.0, 0.0, 0.0\n",
    "\n",
    "    # Word-level counts for all words\n",
    "    word_counts = defaultdict(lambda: {\"TP\":0, \"FP\":0, \"FN\":0})\n",
    "\n",
    "    # =============================\n",
    "    # Load Silero model ONCE\n",
    "    # =============================\n",
    "    device = torch.device(\"cpu\")\n",
    "    model, decoder, utils = torch.hub.load(\n",
    "        repo_or_dir=\"snakers4/silero-models\",\n",
    "        model=\"silero_stt\",\n",
    "        language=\"en\",\n",
    "        device=device\n",
    "    )\n",
    "    (_, _, _, prepare_model_input) = utils\n",
    "\n",
    "    # =============================\n",
    "    # Process each sentence\n",
    "    # =============================\n",
    "    for sentence_id in range(1, num_sentences+1):\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"Processing sentence {sentence_id}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        audio_path = audio_dir\n",
    "\n",
    "        reference_text = load_reference_by_id(transcript_path, sentence_id)\n",
    "        print(\"\\nReference text:\", reference_text)\n",
    "\n",
    "        recognized_text, processing_time, audio_duration = transcribe_audio(model, decoder, prepare_model_input, audio_path)\n",
    "        print(\"Recognized text:\", recognized_text)\n",
    "\n",
    "        ref_tokens = tokenize_with_punctuation(reference_text)\n",
    "        rec_tokens = tokenize_with_punctuation(recognized_text)\n",
    "\n",
    "        ops = list(align_words(ref_tokens, rec_tokens))\n",
    "\n",
    "        # Update word-level counts\n",
    "        for op in ops:\n",
    "            if op[0] == \"CORRECT\":\n",
    "                word_counts[op[1]][\"TP\"] += 1\n",
    "            elif op[0] == \"SUB\":\n",
    "                ref_w, hyp_w = op[1], op[2]\n",
    "                word_counts[ref_w][\"FN\"] += 1\n",
    "                word_counts[hyp_w][\"FP\"] += 1\n",
    "            elif op[0] == \"DEL\":\n",
    "                word_counts[op[1]][\"FN\"] += 1\n",
    "            elif op[0] == \"INS\":\n",
    "                word_counts[op[1]][\"FP\"] += 1\n",
    "\n",
    "        # WER/WCR\n",
    "        subs = sum(1 for o in ops if o[0]==\"SUB\")\n",
    "        dels = sum(1 for o in ops if o[0]==\"DEL\")\n",
    "        ins = sum(1 for o in ops if o[0]==\"INS\")\n",
    "        wer = (subs + dels + ins)/len(ref_tokens)\n",
    "        wcr = (len(ref_tokens) - subs - dels)/len(ref_tokens)\n",
    "\n",
    "        wer_list.append(wer)\n",
    "        wcr_list.append(wcr)\n",
    "        total_wer += wer\n",
    "        total_wcr += wcr\n",
    "        rtf = processing_time / audio_duration\n",
    "        rtf_list.append(rtf)\n",
    "        total_rtf += rtf\n",
    "\n",
    "        print(f\"WER: {wer:.2%}, WCR: {wcr:.2%}, Audio dur: {audio_duration:.2f}s, Processing: {processing_time:.2f}s, RTF: {rtf:.3f}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # Per-word metrics for TARGET_WORD\n",
    "    # =========================================================\n",
    "    TP = word_counts[TARGET_WORD][\"TP\"]\n",
    "    FP = word_counts[TARGET_WORD][\"FP\"]\n",
    "    FN = word_counts[TARGET_WORD][\"FN\"]\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    f1 = (2*precision*recall/(precision+recall)) if (precision+recall) > 0 else 0.0\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Metrics for word '{TARGET_WORD}': Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # Macro / Micro averages over vocabulary\n",
    "    # =========================================================\n",
    "    macro_prec = 0.0\n",
    "    macro_rec = 0.0\n",
    "    for w, counts in word_counts.items():\n",
    "        TP_w, FP_w, FN_w = counts[\"TP\"], counts[\"FP\"], counts[\"FN\"]\n",
    "        macro_prec += TP_w / (TP_w + FP_w) if (TP_w + FP_w) > 0 else 0\n",
    "        macro_rec += TP_w / (TP_w + FN_w) if (TP_w + FN_w) > 0 else 0\n",
    "    macro_prec /= len(word_counts)\n",
    "    macro_rec /= len(word_counts)\n",
    "\n",
    "    total_TP = sum(c[\"TP\"] for c in word_counts.values())\n",
    "    total_FP = sum(c[\"FP\"] for c in word_counts.values())\n",
    "    total_FN = sum(c[\"FN\"] for c in word_counts.values())\n",
    "    micro_prec = total_TP / (total_TP + total_FP) if (total_TP + total_FP) > 0 else 0\n",
    "    micro_rec = total_TP / (total_TP + total_FN) if (total_TP + total_FN) > 0 else 0\n",
    "\n",
    "    print(\"\\nMacro-averaged: Precision={:.3f}, Recall={:.3f}\".format(macro_prec, macro_rec))\n",
    "    print(\"Micro-averaged: Precision={:.3f}, Recall={:.3f}\".format(micro_prec, micro_rec))\n",
    "\n",
    "    # =========================================================\n",
    "    # Average WER/WCR/RTF\n",
    "    # =========================================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"AVERAGE WER: {total_wer/num_sentences:.2%}\")\n",
    "    print(f\"AVERAGE WCR: {total_wcr/num_sentences:.2%}\")\n",
    "    print(f\"AVERAGE RTF: {total_rtf/num_sentences:.3f}\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ed56158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ayham/.cache\\torch\\hub\\snakers4_silero-models_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing sentence 1\n",
      "============================================================\n",
      "\n",
      "Reference text: The Annual Bulletin of the Comparative Law Bureau of the American Bar Association was an American specialty law journal.\n",
      "Recognized text: that promise i do wish we could chat but coming i'm having an old old friend for the by\n",
      "WER: 100.00%, WCR: 5.00%, Audio dur: 10.99s, Processing: 0.91s, RTF: 0.083\n",
      "\n",
      "============================================================\n",
      "Metrics for word 'mute': Precision=0.000, Recall=0.000, F1=0.000\n",
      "\n",
      "Macro-averaged: Precision=0.029, Recall=0.029\n",
      "Micro-averaged: Precision=0.048, Recall=0.050\n",
      "\n",
      "============================================================\n",
      "AVERAGE WER: 100.00%\n",
      "AVERAGE WCR: 5.00%\n",
      "AVERAGE RTF: 0.083\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from scipy.signal import resample_poly\n",
    "from collections import defaultdict\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "TARGET_WORD = \"mute\"   # word of interest (case-sensitive)\n",
    "audio_dir = r\"C:\\Users\\ayham\\Desktop\\Downloads\\live_demo_dataset\\task3.wav\"\n",
    "transcript_path = r\"C:\\Users\\ayham\\Speech-Recognation-App\\2-c.txt\"\n",
    "num_sentences = 1\n",
    "\n",
    "# =========================================================\n",
    "# Load reference sentence by ID\n",
    "# =========================================================\n",
    "def load_reference_by_id(path: str, sentence_id: int) -> str:\n",
    "    prefix = f\"{sentence_id}:\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(prefix):\n",
    "                text = line[len(prefix):].strip()\n",
    "                text = re.sub(r\"\\(.*?\\)\", \"\", text).strip()\n",
    "                return text\n",
    "    raise ValueError(f\"Sentence ID {sentence_id} not found in transcript file\")\n",
    "\n",
    "# =========================================================\n",
    "# Punctuation-aware tokenizer\n",
    "# =========================================================\n",
    "def tokenize_with_punctuation(text: str) -> list[str]:\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
    "\n",
    "# =========================================================\n",
    "# Word-level alignment (Levenshtein)\n",
    "# =========================================================\n",
    "def align_words(ref_tokens, hyp_tokens):\n",
    "    n, m = len(ref_tokens), len(hyp_tokens)\n",
    "    dp = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "\n",
    "    for i in range(n + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(m + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            if ref_tokens[i - 1] == hyp_tokens[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(\n",
    "                    dp[i - 1][j],\n",
    "                    dp[i][j - 1],\n",
    "                    dp[i - 1][j - 1]\n",
    "                )\n",
    "\n",
    "    i, j = n, m\n",
    "    ops = []\n",
    "    while i > 0 or j > 0:\n",
    "        if i > 0 and j > 0 and ref_tokens[i - 1] == hyp_tokens[j - 1]:\n",
    "            ops.append((\"CORRECT\", ref_tokens[i - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and j > 0 and dp[i][j] == dp[i - 1][j - 1] + 1:\n",
    "            ops.append((\"SUB\", ref_tokens[i - 1], hyp_tokens[j - 1]))\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and dp[i][j] == dp[i - 1][j] + 1:\n",
    "            ops.append((\"DEL\", ref_tokens[i - 1]))\n",
    "            i -= 1\n",
    "        else:\n",
    "            ops.append((\"INS\", hyp_tokens[j - 1]))\n",
    "            j -= 1\n",
    "\n",
    "    return reversed(ops)\n",
    "\n",
    "# =========================================================\n",
    "# Silero STT transcription\n",
    "# =========================================================\n",
    "def transcribe_audio(model, decoder, prepare_model_input, path: str):\n",
    "    start_time = time.time()\n",
    "    audio, sr = sf.read(path)\n",
    "    if audio.ndim > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    if sr != 16000:\n",
    "        audio = resample_poly(audio, 16000, sr)\n",
    "        sr = 16000\n",
    "\n",
    "    audio_tensor = torch.from_numpy(audio).float().unsqueeze(0)\n",
    "    input_tensor = prepare_model_input(audio_tensor, device=\"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    recognized_text = decoder(output[0].cpu())\n",
    "    processing_time = time.time() - start_time\n",
    "    return recognized_text, processing_time, len(audio)/sr\n",
    "\n",
    "# =========================================================\n",
    "# MAIN\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    wer_list, wcr_list, rtf_list = [], [], []\n",
    "    total_wer, total_wcr, total_rtf = 0.0, 0.0, 0.0\n",
    "\n",
    "    # Word-level counts for all words\n",
    "    word_counts = defaultdict(lambda: {\"TP\":0, \"FP\":0, \"FN\":0})\n",
    "\n",
    "    # =============================\n",
    "    # Load Silero model ONCE\n",
    "    # =============================\n",
    "    device = torch.device(\"cpu\")\n",
    "    model, decoder, utils = torch.hub.load(\n",
    "        repo_or_dir=\"snakers4/silero-models\",\n",
    "        model=\"silero_stt\",\n",
    "        language=\"en\",\n",
    "        device=device\n",
    "    )\n",
    "    (_, _, _, prepare_model_input) = utils\n",
    "\n",
    "    # =============================\n",
    "    # Process each sentence\n",
    "    # =============================\n",
    "    for sentence_id in range(1, num_sentences+1):\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"Processing sentence {sentence_id}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        audio_path = audio_dir\n",
    "\n",
    "        reference_text = load_reference_by_id(transcript_path, sentence_id)\n",
    "        print(\"\\nReference text:\", reference_text)\n",
    "\n",
    "        recognized_text, processing_time, audio_duration = transcribe_audio(model, decoder, prepare_model_input, audio_path)\n",
    "        print(\"Recognized text:\", recognized_text)\n",
    "\n",
    "        ref_tokens = tokenize_with_punctuation(reference_text)\n",
    "        rec_tokens = tokenize_with_punctuation(recognized_text)\n",
    "\n",
    "        ops = list(align_words(ref_tokens, rec_tokens))\n",
    "\n",
    "        # Update word-level counts\n",
    "        for op in ops:\n",
    "            if op[0] == \"CORRECT\":\n",
    "                word_counts[op[1]][\"TP\"] += 1\n",
    "            elif op[0] == \"SUB\":\n",
    "                ref_w, hyp_w = op[1], op[2]\n",
    "                word_counts[ref_w][\"FN\"] += 1\n",
    "                word_counts[hyp_w][\"FP\"] += 1\n",
    "            elif op[0] == \"DEL\":\n",
    "                word_counts[op[1]][\"FN\"] += 1\n",
    "            elif op[0] == \"INS\":\n",
    "                word_counts[op[1]][\"FP\"] += 1\n",
    "\n",
    "        # WER/WCR\n",
    "        subs = sum(1 for o in ops if o[0]==\"SUB\")\n",
    "        dels = sum(1 for o in ops if o[0]==\"DEL\")\n",
    "        ins = sum(1 for o in ops if o[0]==\"INS\")\n",
    "        wer = (subs + dels + ins)/len(ref_tokens)\n",
    "        wcr = (len(ref_tokens) - subs - dels)/len(ref_tokens)\n",
    "\n",
    "        wer_list.append(wer)\n",
    "        wcr_list.append(wcr)\n",
    "        total_wer += wer\n",
    "        total_wcr += wcr\n",
    "        rtf = processing_time / audio_duration\n",
    "        rtf_list.append(rtf)\n",
    "        total_rtf += rtf\n",
    "\n",
    "        print(f\"WER: {wer:.2%}, WCR: {wcr:.2%}, Audio dur: {audio_duration:.2f}s, Processing: {processing_time:.2f}s, RTF: {rtf:.3f}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # Per-word metrics for TARGET_WORD\n",
    "    # =========================================================\n",
    "    TP = word_counts[TARGET_WORD][\"TP\"]\n",
    "    FP = word_counts[TARGET_WORD][\"FP\"]\n",
    "    FN = word_counts[TARGET_WORD][\"FN\"]\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    f1 = (2*precision*recall/(precision+recall)) if (precision+recall) > 0 else 0.0\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Metrics for word '{TARGET_WORD}': Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # Macro / Micro averages over vocabulary\n",
    "    # =========================================================\n",
    "    macro_prec = 0.0\n",
    "    macro_rec = 0.0\n",
    "    for w, counts in word_counts.items():\n",
    "        TP_w, FP_w, FN_w = counts[\"TP\"], counts[\"FP\"], counts[\"FN\"]\n",
    "        macro_prec += TP_w / (TP_w + FP_w) if (TP_w + FP_w) > 0 else 0\n",
    "        macro_rec += TP_w / (TP_w + FN_w) if (TP_w + FN_w) > 0 else 0\n",
    "    macro_prec /= len(word_counts)\n",
    "    macro_rec /= len(word_counts)\n",
    "\n",
    "    total_TP = sum(c[\"TP\"] for c in word_counts.values())\n",
    "    total_FP = sum(c[\"FP\"] for c in word_counts.values())\n",
    "    total_FN = sum(c[\"FN\"] for c in word_counts.values())\n",
    "    micro_prec = total_TP / (total_TP + total_FP) if (total_TP + total_FP) > 0 else 0\n",
    "    micro_rec = total_TP / (total_TP + total_FN) if (total_TP + total_FN) > 0 else 0\n",
    "\n",
    "    print(\"\\nMacro-averaged: Precision={:.3f}, Recall={:.3f}\".format(macro_prec, macro_rec))\n",
    "    print(\"Micro-averaged: Precision={:.3f}, Recall={:.3f}\".format(micro_prec, micro_rec))\n",
    "\n",
    "    # =========================================================\n",
    "    # Average WER/WCR/RTF\n",
    "    # =========================================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"AVERAGE WER: {total_wer/num_sentences:.2%}\")\n",
    "    print(f\"AVERAGE WCR: {total_wcr/num_sentences:.2%}\")\n",
    "    print(f\"AVERAGE RTF: {total_rtf/num_sentences:.3f}\")\n",
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
